"""UNIFIED CONTENT ENRICHER - Enriquecimiento LLM centralizado para todas las fuentes.

¿QUÉ HACE?
-----------
Acepta texto plano de cualquier fuente (scraping, email, Perplexity, manual, etc.) y lo
enriquece con metadata estructurada usando Groq Llama 3.3 70B.

¿QUÉ GENERA?
------------
- title: Título claro y conciso
- summary: Resumen de 2-3 frases
- tags: Lista de etiquetas relevantes
- category: Categoría única (política, economía, sociedad, cultura, etc.)
- atomic_statements: Hechos atómicos extraídos del texto

¿CUÁNDO SE USA?
---------------
- Scraping: Después de parsear HTML, antes de guardar
- Perplexity: Después de fetch JSON, antes de ingest
- Email: Después de combinar body+attachments
- Manual: Cuando usuario sube texto sin metadata

¿POR QUÉ CENTRALIZADO?
----------------------
- ✅ Categorización consistente en todas las fuentes
- ✅ Un solo lugar para cambiar lógica de enrichment
- ✅ Tracking de costes LLM centralizado
- ✅ Permite pre-filling (skip LLM si ya tienes título, etc.)
- ✅ Fácil testing y mantenimiento

EJEMPLO DE USO:
---------------
enriched = await enrich_content(
    raw_text="Texto del artículo...",
    source_type="scraping",
    company_id="uuid-123",
    pre_filled={"title": "Título ya conocido"}  # Skip LLM para título
)
# Returns: {title, summary, tags, category, atomic_statements, enrichment_cost_usd, enrichment_model}
"""

from typing import Dict, Any, Optional, List
from utils.logger import get_logger
from utils.llm_client import get_llm_client

logger = get_logger("content_enricher")


async def enrich_content(
    raw_text: str,
    source_type: str,
    company_id: str,
    pre_filled: Optional[Dict[str, Any]] = None
) -> Dict[str, Any]:
    """Universal content enrichment - generates missing metadata via LLM.
    
    This is the ONLY place where content categorization and enrichment happens.
    All source types (manual, scraping, email, perplexity, etc.) should use this.
    
    Args:
        raw_text: Full text content (transcription, email body, HTML, etc.)
        source_type: Origin type for logging (manual, scraping, email, perplexity, etc.)
        company_id: Company UUID for cost tracking
        pre_filled: Optional pre-generated fields that should NOT be regenerated
            Example: {"title": "User Title", "tags": ["custom"]}
            Any field in pre_filled will NOT be regenerated by LLM
    
    Returns:
        Dict with:
            - title: str
            - summary: str
            - tags: List[str]
            - category: str (política, economía, sociedad, cultura, deportes, tecnología,
                             medio_ambiente, infraestructuras, seguridad, salud, turismo,
                             internacional, general)
            - atomic_statements: List[Dict] (each with 'statement' and 'confidence')
            - enrichment_cost_usd: float
            - enrichment_model: str
    
    Example:
        # Manual source (user provides title)
        enriched = await enrich_content(
            raw_text="El ayuntamiento aprobó...",
            source_type="manual",
            company_id="uuid-123",
            pre_filled={"title": "Nuevo presupuesto aprobado"}
        )
        # Returns: {title: "Nuevo presupuesto aprobado", summary: "...", category: "política", ...}
        
        # Scraping source (LLM generates everything)
        enriched = await enrich_content(
            raw_text=html_content,
            source_type="scraping",
            company_id="uuid-123",
            pre_filled={}
        )
        # Returns: {title: "...", summary: "...", category: "...", ...}
    """
    pre_filled = pre_filled or {}
    
    logger.debug("enrichment_start",
        source_type=source_type,
        company_id=company_id,
        text_length=len(raw_text),
        pre_filled_fields=list(pre_filled.keys())
    )
    
    required_fields = ["title", "summary", "tags", "category", "atomic_statements"]
    
    if all(field in pre_filled for field in required_fields):
        logger.info("enrichment_skipped_all_prefilled",
            source_type=source_type,
            company_id=company_id
        )
        return {
            **pre_filled,
            "enrichment_cost_usd": 0.0,
            "enrichment_model": "none"
        }
    
    try:
        llm_client = get_llm_client()
        
        logger.debug("calling_llm_analyze_atomic",
            source_type=source_type,
            text_preview=raw_text[:100]
        )
        
        llm_result = await llm_client.analyze_atomic(
            text=raw_text[:8000],
            company_id=company_id
        )
        
        enriched = {
            "title": pre_filled.get("title") or llm_result.get("title") or "Sin título",
            "summary": pre_filled.get("summary") or llm_result.get("summary") or "",
            "tags": pre_filled.get("tags") or llm_result.get("tags") or [],
            "category": pre_filled.get("category") or llm_result.get("category") or "general",
            "atomic_statements": pre_filled.get("atomic_statements") or llm_result.get("atomic_statements") or [],
            "locations": pre_filled.get("locations") or llm_result.get("locations") or [],
            "enrichment_cost_usd": llm_result.get("cost_usd", 0.0),
            "enrichment_model": llm_result.get("model", "gpt-4o-mini")
        }
        
        fields_prefilled = [k for k in required_fields if k in pre_filled]
        fields_generated = [k for k in required_fields if k not in pre_filled]
        
        logger.info("content_enriched",
            source_type=source_type,
            company_id=company_id,
            fields_prefilled=fields_prefilled,
            fields_generated=fields_generated,
            cost_usd=enriched["enrichment_cost_usd"],
            category=enriched["category"],
            tags_count=len(enriched["tags"]),
            atomic_count=len(enriched["atomic_statements"])
        )
        
        return enriched
        
    except Exception as e:
        logger.error("content_enrichment_failed",
            source_type=source_type,
            company_id=company_id,
            error=str(e),
            error_type=type(e).__name__,
            text_preview=raw_text[:200]
        )
        
        # Fallback: basic extraction from raw text
        title_fallback = pre_filled.get("title")
        if not title_fallback or title_fallback == "":
            # Try to extract first line or first 100 chars as title
            first_line = raw_text.split('\n')[0].strip()[:100]
            title_fallback = first_line if first_line else "Contenido sin título"
        
        summary_fallback = pre_filled.get("summary")
        if not summary_fallback:
            # Use first 500 chars as summary
            summary_fallback = raw_text[:500].strip()
        
        logger.warn("using_fallback_enrichment",
            title=title_fallback[:50],
            has_summary=bool(summary_fallback),
            error_type=type(e).__name__
        )
        
        return {
            "title": title_fallback,
            "summary": summary_fallback,
            "tags": pre_filled.get("tags", []),
            "category": pre_filled.get("category", "general"),
            "atomic_statements": pre_filled.get("atomic_statements", []),
            "enrichment_cost_usd": 0.0,
            "enrichment_model": "fallback"
        }


async def enrich_content_batch(
    items: List[Dict[str, Any]],
    source_type: str,
    company_id: str
) -> List[Dict[str, Any]]:
    """Batch enrichment for multiple content items.
    
    Useful for multi-noticia scenarios (scraping index pages, perplexity multiple news).
    
    Args:
        items: List of dicts with 'raw_text' and optional 'pre_filled'
            Example: [
                {"raw_text": "...", "pre_filled": {"title": "..."}},
                {"raw_text": "...", "pre_filled": {}}
            ]
        source_type: Origin type
        company_id: Company UUID
    
    Returns:
        List of enriched content dicts
    """
    logger.info("batch_enrichment_start",
        source_type=source_type,
        company_id=company_id,
        item_count=len(items)
    )
    
    enriched_items = []
    
    for i, item in enumerate(items):
        try:
            enriched = await enrich_content(
                raw_text=item.get("raw_text", ""),
                source_type=source_type,
                company_id=company_id,
                pre_filled=item.get("pre_filled", {})
            )
            enriched_items.append(enriched)
            
        except Exception as e:
            logger.error("batch_enrichment_item_failed",
                source_type=source_type,
                item_index=i,
                error=str(e)
            )
            enriched_items.append({
                "title": "Error al procesar",
                "summary": "",
                "tags": [],
                "category": "general",
                "atomic_statements": [],
                "enrichment_cost_usd": 0.0,
                "enrichment_model": "error"
            })
    
    total_cost = sum(item["enrichment_cost_usd"] for item in enriched_items)
    
    logger.info("batch_enrichment_completed",
        source_type=source_type,
        company_id=company_id,
        total_items=len(items),
        successful_items=len([i for i in enriched_items if i["enrichment_model"] != "error"]),
        total_cost_usd=total_cost
    )
    
    return enriched_items
