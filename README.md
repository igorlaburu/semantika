# semantika

**Pipeline semÃ¡ntico multi-tenant para agregaciÃ³n y anÃ¡lisis de noticias en espaÃ±ol/euskera**

Sistema inteligente para ingesta, procesamiento y bÃºsqueda hÃ­brida de contenido con:
- ğŸ”’ Multi-tenancy seguro con RLS (Row-Level Security)
- ğŸ” BÃºsqueda hÃ­brida (semantic + keyword) con query expansion
- ğŸŒŠ Pool compartido con discovery automÃ¡tico de fuentes
- ğŸ¤– Enriquecimiento LLM (Claude 3.5 Sonnet, Groq Llama 3.3)
- ğŸ“Š Embeddings locales FastEmbed (768d multilingual)
- â° Scheduler para scraping e ingesta automÃ¡tica
- ğŸŒ Web scraping + Perplexity + Email monitoring

---

## ğŸš€ Quick Start

### 1. **Servicios Externos Requeridos**

- **[Supabase](https://supabase.com)**: PostgreSQL + pgvector (embeddings)
- **[OpenRouter](https://openrouter.ai)**: Claude 3.5 Sonnet (enriquecimiento)
- **[Groq](https://console.groq.com)**: Llama 3.3 70B (gratis, anÃ¡lisis rÃ¡pido)

### 2. **Deploy en VPS**

```bash
# Clonar repositorio
git clone https://github.com/igorlaburu/semantika.git
cd semantika

# Configurar variables de entorno
cp .env.example .env
# Editar .env con tus credenciales

# Levantar servicios
docker-compose up -d --build

# Verificar
curl http://localhost:8000/health
```

**Deploy automÃ¡tico**: Push a `main` â†’ GitHub Actions despliega a VPS (ver [AUTO_DEPLOY_GUIDE.md](./AUTO_DEPLOY_GUIDE.md))

### 3. **Crear Primera OrganizaciÃ³n**

```bash
# Onboarding automÃ¡tico vÃ­a API
curl -X POST https://api.ekimen.ai/onboard/company \
  -H "Content-Type: application/json" \
  -d '{
    "company_name": "Mi Empresa",
    "company_cif": "B12345678",
    "email": "admin@miempresa.com",
    "password": "contraseÃ±a-segura",
    "full_name": "Admin Usuario"
  }'

# Respuesta incluye JWT token para autenticaciÃ³n
```

### 4. **Probar API**

```bash
# Health check
curl https://api.ekimen.ai/health

# Login
curl -X POST https://api.ekimen.ai/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email": "admin@miempresa.com", "password": "contraseÃ±a-segura"}'

# Guardar JWT token
export JWT="eyJhbGc..."

# Buscar en contexto privado + pool
curl -X POST https://api.ekimen.ai/api/v1/context-units/search-vector \
  -H "Authorization: Bearer $JWT" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "alcalde bilbao",
    "limit": 10,
    "threshold": 0.18,
    "filters": {"include_pool": true}
  }'
```

---

## ğŸ“š Arquitectura

### Sistema Unificado PostgreSQL + pgvector

**Base de datos Ãºnica** (Supabase):
- âœ… Config + vectores en una sola BD
- âœ… RLS policies para multi-tenancy seguro
- âœ… BÃºsqueda hÃ­brida (semantic + keyword) en una query
- âœ… Joins nativos (context_units + sources + companies)

**Tablas principales**:
- `press_context_units`: Noticias procesadas (company-specific + pool)
- `web_context_units`: Monitoring web (subvenciones, formularios)
- `sources`: ConfiguraciÃ³n de fuentes de scraping
- `companies`, `users`, `organizations`: Multi-tenancy

### Pool Compartido

**UUID Pool**: `99999999-9999-9999-9999-999999999999`

**Flujo automÃ¡tico**:
1. **Discovery** (cada 3 dÃ­as): GNews API â†’ LLM Groq identifica fuentes originales â†’ Extrae index URLs â†’ Guarda en `discovered_sources`
2. **Ingesta** (cada hora): Scrape fuentes descubiertas â†’ Enriquece con LLM â†’ Guarda en `press_context_units` (pool)
3. **Acceso**: Todos los clientes buscan con `include_pool=true`

### BÃºsqueda HÃ­brida

**Endpoint**: `POST /api/v1/context-units/search-vector`

**3 capas**:
1. **Query expansion**: Cache (1h) + diccionario local (espaÃ±ol/euskera) + LLM Groq (solo queries cortos)
2. **Semantic search**: pgvector cosine similarity (FastEmbed 768d, threshold 0.18)
3. **Keyword search**: PostgreSQL full-text search (Spanish config)

**Re-ranking**: `0.7 * semantic + 0.3 * keyword`

**Performance**:
- Latencia: 150-200ms (con cache) / 300-400ms (sin cache)
- Costo: $0 (Groq gratis, FastEmbed local)

### Embeddings FastEmbed

**Modelo**: `sentence-transformers/paraphrase-multilingual-mpnet-base-v2`
- Dimensiones: 768
- Idiomas: 50+ (espaÃ±ol, euskera, catalÃ¡n, gallego, inglÃ©s...)
- Velocidad: ~150ms por query (CPU)
- Costo: $0 (100% local, sin API)

---

## ğŸ”Œ API Endpoints

### AutenticaciÃ³n

#### `POST /onboard/company`
Crear nueva organizaciÃ³n + usuario admin.

```bash
curl -X POST https://api.ekimen.ai/onboard/company \
  -H "Content-Type: application/json" \
  -d '{
    "company_name": "Empresa SL",
    "company_cif": "B12345678",
    "email": "admin@empresa.com",
    "password": "pass",
    "full_name": "Admin User"
  }'
```

**Respuesta**: JWT token + company_id + user_id

#### `POST /auth/login`
Login con email + password.

```bash
curl -X POST https://api.ekimen.ai/auth/login \
  -H "Content-Type: application/json" \
  -d '{"email": "user@empresa.com", "password": "pass"}'
```

**Respuesta**: JWT token (vÃ¡lido 7 dÃ­as)

### Context Units (Noticias)

#### `GET /api/v1/context-units`
Listar context units con filtros.

```bash
curl "https://api.ekimen.ai/api/v1/context-units?limit=20&timePeriod=24h&include_pool=true" \
  -H "Authorization: Bearer $JWT"
```

**ParÃ¡metros**:
- `limit`: Max resultados (1-100, default 20)
- `offset`: PaginaciÃ³n (default 0)
- `timePeriod`: `24h`, `week`, `month`, `all`
- `category`: Filtro por categorÃ­a
- `include_pool`: Incluir contenido pool (default false)

#### `POST /api/v1/context-units/search-vector`
BÃºsqueda hÃ­brida (semantic + keyword).

```bash
curl -X POST https://api.ekimen.ai/api/v1/context-units/search-vector \
  -H "Authorization: Bearer $JWT" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "lehendakari reuniÃ³n empresarios",
    "limit": 10,
    "threshold": 0.18,
    "filters": {"include_pool": true, "category": "polÃ­tica"}
  }'
```

**Respuesta**:
```json
{
  "query": "lehendakari reuniÃ³n empresarios",
  "query_expansion": {
    "original": "lehendakari reuniÃ³n empresarios",
    "expanded_terms": ["lehendakari", "presidente", "lehendakaritza", "reuniÃ³n", "bilera", "empresarios"],
    "terms_count": 6
  },
  "results": [{
    "id": "uuid",
    "title": "El Lehendakari se reÃºne...",
    "summary": "...",
    "semantic_score": 0.82,
    "keyword_score": 0.15,
    "combined_score": 0.62,
    "category": "polÃ­tica",
    "created_at": "2025-12-09T..."
  }],
  "count": 10,
  "search_method": "hybrid_semantic_keyword",
  "query_time_ms": 187
}
```

#### `GET /api/v1/context-units/{id}`
Obtener context unit por ID.

### Sources (Fuentes)

#### `GET /api/v1/sources`
Listar fuentes configuradas.

#### `POST /api/v1/sources`
Crear nueva fuente de scraping.

```bash
curl -X POST https://api.ekimen.ai/api/v1/sources \
  -H "Authorization: Bearer $JWT" \
  -H "Content-Type: application/json" \
  -d '{
    "source_name": "Noticias Empresa",
    "source_type": "scraping",
    "config": {
      "url": "https://empresa.com/noticias",
      "frequency_minutes": 60
    }
  }'
```

### Processing (Workflows)

#### `POST /process/micro-edit`
Micro-ediciÃ³n de texto con LLM.

```bash
curl -X POST https://api.ekimen.ai/process/micro-edit \
  -H "Authorization: Bearer $JWT" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Texto original...",
    "command": "Corrige errores ortogrÃ¡ficos",
    "params": {"temperature": 0.3}
  }'
```

#### `POST /process/redact-news-rich`
RedacciÃ³n de noticia con estructura rich.

---

## ğŸ—ï¸ Arquitectura Docker

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  semantika-api (8000)   â”‚  â—„â”€â”€ FastAPI + Auth JWT
â”‚  - /api/v1/*            â”‚
â”‚  - /process/*           â”‚
â”‚  - /auth/*              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”œâ”€â”€â–º Supabase PostgreSQL + pgvector
        â”‚    - press_context_units (768d embeddings)
        â”‚    - companies, users, sources
        â”‚    - RLS policies multi-tenant
        â”‚
        â”œâ”€â”€â–º FastEmbed Local (768d)
        â”‚    - paraphrase-multilingual-mpnet-base-v2
        â”‚    - ~150ms per query
        â”‚
        â”œâ”€â”€â–º OpenRouter
        â”‚    - Claude 3.5 Sonnet (enriquecimiento)
        â”‚
        â””â”€â”€â–º Groq (gratis)
             - Llama 3.3 70B (anÃ¡lisis, query expansion)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ semantika-scheduler     â”‚  â—„â”€â”€ APScheduler
â”‚ - Discovery (3 dÃ­as)    â”‚
â”‚ - Ingesta Pool (1h)     â”‚
â”‚ - Scraping sources      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”’ Seguridad

### Multi-tenancy con RLS

**Row-Level Security** en Supabase:
```sql
-- Context units: Solo acceso a propios + pool
CREATE POLICY select_own_company_context_units 
ON press_context_units FOR SELECT
USING (
  company_id = current_user_company_id() 
  OR company_id = '99999999-9999-9999-9999-999999999999'::uuid
);
```

### Guardrails de Contenido

1. **Quality gate**: MÃ­nimo 2 atomic statements
2. **DeduplicaciÃ³n semÃ¡ntica**: Threshold 0.98
3. **Robots.txt**: Web scraper respeta directivas
4. **TÃ­tulo genÃ©rico**: LLM extrae tÃ­tulo real si HTML es genÃ©rico

### AutenticaciÃ³n

- **JWT tokens** (Supabase Auth) - 7 dÃ­as validez
- **Refresh tokens** - RotaciÃ³n automÃ¡tica
- **RLS policies** - Aislamiento por company_id

---

## ğŸ“Š Monitoreo

### Logs
```bash
# Ver logs API
docker logs -f ekimen_semantika-semantika-api-1

# Ver logs Scheduler
docker logs -f ekimen_semantika-semantika-scheduler-1

# Logs JSON estructurados
{"level": "INFO", "timestamp": "...", "service": "hybrid_search", "query": "..."}
```

### MÃ©tricas

- **Supabase Dashboard**: Queries, storage, usuarios
- **OpenRouter Dashboard**: Usage LLM + costos
- **Groq Console**: Requests (gratis, sin coste)

---

## ğŸ’° Costos Estimados

- **Supabase**: $25/mes (Pro plan para producciÃ³n)
- **OpenRouter**: $10-30/mes (Claude 3.5 Sonnet uso medio)
- **Groq**: $0 (gratis, rate limits generosos)
- **FastEmbed**: $0 (local, sin API)
- **VPS**: $10-50/mes (segÃºn recursos)

**Total**: $45-105/mes para uso medio (~1000 bÃºsquedas/dÃ­a)

---

## ğŸ§ª Testing

```bash
# Unit tests
./run_tests.sh

# O manualmente
python3 -m pytest tests/ -v

# Con coverage
python3 -m pytest tests/ --cov=utils --cov=sources --cov-report=html
```

---

## ğŸ“ DocumentaciÃ³n

- **[CLAUDE.md](./CLAUDE.md)** - GuÃ­a para Claude Code (desarrollo)
- **[AUTO_DEPLOY_GUIDE.md](./AUTO_DEPLOY_GUIDE.md)** - Deploy automÃ¡tico GitHub Actions
- **[CLI_USAGE.md](./CLI_USAGE.md)** - Comandos CLI
- **[SECURITY.md](./SECURITY.md)** - GuÃ­a de seguridad
- **[requirements.md](./requirements.md)** - Arquitectura tÃ©cnica completa

---

## ğŸš§ Roadmap

### âœ… Implementado (v1.0)
- âœ… PostgreSQL + pgvector unificado
- âœ… BÃºsqueda hÃ­brida (semantic + keyword)
- âœ… Query expansion con cache + Groq
- âœ… FastEmbed local 768d
- âœ… Pool compartido con discovery automÃ¡tico
- âœ… Multi-tenancy con RLS
- âœ… Web scraping + Perplexity
- âœ… Micro-edit + redacciÃ³n noticias
- âœ… Auth JWT + onboarding

### ğŸ”œ PrÃ³ximamente (v2.0)
- [ ] Frontend Dashboard (React/Vue)
- [ ] Alertas personalizadas (email/webhooks)
- [ ] Analytics y reportes
- [ ] API connectors (EFE, Reuters, WordPress)
- [ ] Cache Redis para bÃºsquedas
- [ ] Rate limiting por company

---

## ğŸ“„ Licencia

MIT License - ver [LICENSE](./LICENSE)

---

## ğŸ¤ Contribuir

1. Fork el repo
2. Crea branch: `git checkout -b feature/nueva-feature`
3. Commit: `git commit -m 'Add nueva feature'`
4. Push: `git push origin feature/nueva-feature`
5. Abre Pull Request

---

## ğŸ“ Soporte

- **Issues**: [github.com/igorlaburu/semantika/issues](https://github.com/igorlaburu/semantika/issues)
- **DocumentaciÃ³n**: Ver `*.md` en raÃ­z
- **Logs**: `docker logs -f ekimen_semantika-semantika-api-1`

---

**Built with â¤ï¸  using FastAPI, PostgreSQL, pgvector, FastEmbed, Claude & Groq**
