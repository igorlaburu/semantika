services:
  semantika-api:
    build: .
    command: "uvicorn server:app --host 0.0.0.0 --port 8000"
    environment:
      - SUPABASE_URL
      - SUPABASE_KEY
      - QDRANT_URL
      - QDRANT_API_KEY
      - OPENROUTER_API_KEY
      - FAL_AI_API_KEY
      - TWITTER_CONSUMER_KEY
      - TWITTER_CONSUMER_SECRET
      - LINKEDIN_CLIENT_ID
      - LINKEDIN_CLIENT_SECRET
      - API_BASE_URL
      - CREDENTIALS_ENCRYPTION_KEY
      - QDRANT_COLLECTION_NAME=semantika_prod
      - MCP_SERVER_URL
      - LOG_LEVEL=INFO
    volumes:
      - fastembed_cache:/root/.cache/fastembed  # Cache FastEmbed models
      - whisper_cache:/root/.cache/whisper  # Cache Whisper models
      - images_cache:/app/cache/images  # Persistent image cache
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8000/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  semantika-scheduler:
    build: .
    command: "python scheduler.py"
    environment:
      - SUPABASE_URL
      - SUPABASE_KEY
      - QDRANT_URL
      - QDRANT_API_KEY
      - OPENROUTER_API_KEY
      - FAL_AI_API_KEY
      - TWITTER_CONSUMER_KEY
      - TWITTER_CONSUMER_SECRET
      - LINKEDIN_CLIENT_ID
      - LINKEDIN_CLIENT_SECRET
      - API_BASE_URL
      - CREDENTIALS_ENCRYPTION_KEY
      - QDRANT_COLLECTION_NAME=semantika_prod
      - LOG_LEVEL=INFO
    volumes:
      - fastembed_cache:/root/.cache/fastembed  # Cache FastEmbed models
      - whisper_cache:/root/.cache/whisper  # Cache Whisper models
      - images_cache:/app/cache/images  # Persistent image cache (shared with API)
    restart: unless-stopped
    depends_on:
      - semantika-api

  semantika-mcp:
    build: .
    command: "python mcp_server.py"
    environment:
      - SUPABASE_URL
      - SUPABASE_KEY
      - OPENROUTER_API_KEY
      - CREDENTIALS_ENCRYPTION_KEY
      - MCP_PORT=8001
      - LOG_LEVEL=INFO
    volumes:
      - fastembed_cache:/root/.cache/fastembed  # Cache FastEmbed models
    restart: unless-stopped
    depends_on:
      - semantika-api
    healthcheck:
      test: ["CMD", "python", "-c", "import requests; requests.get('http://localhost:8001/health', timeout=5)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.semantika-mcp.rule=Host(`api.ekimen.ai`) && PathPrefix(`/mcp`)"
      - "traefik.http.routers.semantika-mcp.entrypoints=https"
      - "traefik.http.routers.semantika-mcp.tls=true"
      - "traefik.http.routers.semantika-mcp.tls.certresolver=letsencrypt"
      - "traefik.http.middlewares.mcp-stripprefix.stripprefix.prefixes=/mcp"
      - "traefik.http.routers.semantika-mcp.middlewares=mcp-stripprefix"
      - "traefik.http.services.semantika-mcp.loadbalancer.server.port=8001"

volumes:
  fastembed_cache:
  whisper_cache:
  images_cache:
