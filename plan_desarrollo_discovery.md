# Plan de Desarrollo: Sistema Discovery de Fuentes

**Fecha:** 2 Diciembre 2024  
**Proyecto:** Semantika - Content Discovery Engine  
**Objetivo:** Sistema auto-evolutivo de descubrimiento y gestiÃ³n de fuentes de contenido original

---

## ğŸ“‹ Resumen Ejecutivo

### Concepto
Crear un sistema que **descubre automÃ¡ticamente** nuevas fuentes de contenido original (ayuntamientos, empresas, fundaciones, asociaciones) a partir de noticias publicadas en grandes medios, evalÃºa su relevancia basÃ¡ndose en uso real, frecuencia y calidad, y optimiza recursos eliminando fuentes que decaen.

### Beneficios
- âœ… Acceso a **contenido original** antes que los medios
- âœ… Escala automÃ¡ticamente sin intervenciÃ³n manual
- âœ… Se auto-optimiza eliminando fuentes irrelevantes
- âœ… Proporciona datos de contacto al periodista para verificaciÃ³n directa
- âœ… Diversifica fuentes evitando dependencia de agregadores

### Costos Estimados
- **Discovery diario:** $1.50/mes
- **Quality evaluations:** $0.60/mes
- **Contact extraction:** $0.90/mes
- **Total:** ~$3/mes

---

## ğŸ¯ Estrategia de Relevancia

### Tres Pilares Simples

**1. Uso del Cliente (40% peso)**
- El periodista publica artÃ­culos usando contenido de esa fuente
- MÃ©trica: `articles_published_count`
- FÃ³rmula: `min(articles_count / 10, 1.0) * 0.4`

**2. Frecuencia de Contenido (30% peso)**
- La fuente publica contenido nuevo regularmente
- MÃ©tricas: `avg_content_frequency_days`, `last_content_date`
- Scoring:
  - â‰¤7 dÃ­as: 1.0 (semanal o mÃ¡s)
  - â‰¤30 dÃ­as: 0.6 (mensual)
  - >30 dÃ­as: 0.3 (irregular)
- Penalizaciones:
  - Sin contenido >60 dÃ­as: Ã— 0.3
  - Sin contenido >30 dÃ­as: Ã— 0.7

**3. Calidad del Contenido (30% peso)**
- LLM evalÃºa riqueza informativa del contenido
- MÃ©trica: `avg_content_quality_score` (0-1)
- FÃ³rmula: `avg_quality_score * 0.3`

### FÃ³rmula Final
```python
relevance_score = (
    min(articles_published / 10, 1.0) * 0.4 +
    frequency_score * frequency_penalty * 0.3 +
    avg_quality_score * 0.3
)
```

---

## ğŸ—„ï¸ Estructura de Base de Datos

### Tabla: `discovered_sources`

```sql
CREATE TABLE discovered_sources (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  company_id UUID NOT NULL REFERENCES companies(id),
  
  -- Identidad de la fuente
  url TEXT NOT NULL,
  domain TEXT NOT NULL,
  source_name TEXT NOT NULL,
  source_type TEXT, -- ayuntamiento, empresa, fundacion, asociacion, medio_local
  
  -- Contacto (para el periodista)
  contact_name TEXT,
  contact_email TEXT,
  contact_phone TEXT,
  contact_address TEXT,
  
  -- Estado del ciclo de vida
  status TEXT DEFAULT 'trial', -- trial, active, inactive, archived
  
  -- MÃ©tricas de relevancia (auto-calculadas)
  relevance_score FLOAT DEFAULT 0.5,
  
  -- Factor 1: Uso por clientes
  articles_published_count INT DEFAULT 0,
  last_article_published_at TIMESTAMPTZ,
  
  -- Factor 2: Frecuencia de contenido
  content_items_scraped INT DEFAULT 0,
  last_content_date TIMESTAMPTZ,
  avg_content_frequency_days FLOAT,
  
  -- Factor 3: Calidad del contenido
  avg_content_quality_score FLOAT,
  quality_evaluations_count INT DEFAULT 0,
  
  -- Metadatos de descubrimiento
  discovered_from TEXT, -- perplexity, google_news, manual
  discovered_at TIMESTAMPTZ DEFAULT NOW(),
  first_seen_headline TEXT,
  
  -- Scraping config
  scraping_frequency TEXT DEFAULT 'daily', -- daily, weekly, monthly
  last_scraped_at TIMESTAMPTZ,
  
  -- Lifecycle
  trial_ends_at TIMESTAMPTZ,
  archived_at TIMESTAMPTZ,
  archived_reason TEXT,
  
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW(),
  
  UNIQUE(company_id, url)
);

-- Ãndices
CREATE INDEX idx_discovered_sources_status ON discovered_sources(status);
CREATE INDEX idx_discovered_sources_relevance ON discovered_sources(relevance_score DESC);
CREATE INDEX idx_discovered_sources_company ON discovered_sources(company_id);
CREATE INDEX idx_discovered_sources_last_content ON discovered_sources(last_content_date);
```

---

## ğŸ—ï¸ Arquitectura del Sistema

### Fase 1: Discovery Pipeline (Job Diario - 6:00 UTC)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. EXTRACCIÃ“N DE TITULARES (10-20 noticias)            â”‚
â”‚    - Perplexity API (noticias de Euskadi/Ãlava)        â”‚
â”‚    - Google News scraping (opcional)                   â”‚
â”‚    - Portadas de medios (El Correo, Deia...)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. BÃšSQUEDA DE FUENTE ORIGINAL                         â”‚
â”‚    - Google Search: "tÃ­tulo" + site:.eus/.es           â”‚
â”‚    - Identificar URL original (no medios conocidos)    â”‚
â”‚    - Extraer dominio raÃ­z                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. VALIDACIÃ“N DE FUENTE (inline, no se guarda en BD)   â”‚
â”‚    - âœ… Verificar robots.txt allow                     â”‚
â”‚    - âœ… Detectar copyright restrictivo                 â”‚
â”‚    - âœ… Detectar sala de prensa/noticias (heurÃ­stica)  â”‚
â”‚    - âŒ Si falla â†’ descartar fuente                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EXTRACCIÃ“N DE CONTACTO (LLM)                        â”‚
â”‚    - source_name: Nombre oficial organizaciÃ³n          â”‚
â”‚    - contact_email: Email prensa/contacto              â”‚
â”‚    - contact_phone: TelÃ©fono                           â”‚
â”‚    - contact_address: DirecciÃ³n fÃ­sica                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. EVALUACIÃ“N INICIAL DE CALIDAD (LLM)                 â”‚
â”‚    - Analizar primer contenido encontrado              â”‚
â”‚    - Score 0-1 de riqueza informativa                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. CREAR discovered_source                             â”‚
â”‚    - status: trial                                     â”‚
â”‚    - relevance_score: 0.5 (inicial)                    â”‚
â”‚    - trial_ends_at: NOW() + 30 dÃ­as                    â”‚
â”‚    - Crear source en tabla sources (para scraping)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fase 2: Quality Evaluation (Durante Scraping)

```python
# Cada vez que se scrapea contenido nuevo de una discovered_source:

async def on_content_scraped(discovered_source_id, content_unit):
    """
    Callback cuando se scrapea contenido de una discovered source.
    """
    # 1. Evaluar calidad con LLM
    quality_score = await evaluate_content_quality(content_unit)
    
    # 2. Actualizar mÃ©tricas
    await update_source_metrics(
        discovered_source_id,
        new_quality_score=quality_score,
        content_date=content_unit.created_at
    )
    
    # 3. Recalcular relevance_score
    await recalculate_relevance(discovered_source_id)
    
    # 4. Ajustar frecuencia de scraping si es necesario
    await adjust_scraping_frequency(discovered_source_id)
```

### Fase 3: Usage Tracking (Al Publicar ArtÃ­culo)

```python
# Cuando el periodista publica un artÃ­culo usando context_units:

async def on_article_published(article_id):
    """
    Callback cuando se publica un artÃ­culo.
    """
    # 1. Identificar discovered_sources usadas
    sources_used = await get_sources_from_article(article_id)
    
    # 2. Incrementar articles_published_count
    for source_id in sources_used:
        await increment_usage_count(source_id)
        
    # 3. Recalcular relevance_score
    for source_id in sources_used:
        await recalculate_relevance(source_id)
```

### Fase 4: Lifecycle Management (Job Semanal - Lunes 3:00 UTC)

```python
async def evaluate_source_lifecycle():
    """
    EvalÃºa todas las fuentes y ajusta su estado.
    
    Estados del ciclo de vida:
    - trial: Periodo de prueba (30 dÃ­as)
    - active: Fuente productiva y relevante (score > 0.5)
    - inactive: Sin contenido reciente (score < 0.5)
    - archived: Eliminada del scraping (score < 0.3 por >60 dÃ­as)
    """
    
    # 1. Promocionar trial â†’ active
    # Si trial_ends_at < NOW() y score > 0.5
    await promote_trials_to_active()
    
    # 2. Degradar active â†’ inactive
    # Si no hay contenido nuevo en 60 dÃ­as
    await demote_active_to_inactive()
    
    # 3. Archivar inactive â†’ archived
    # Si llevan >90 dÃ­as sin contenido y score < 0.3
    await archive_inactive_sources()
    
    # 4. Ajustar frecuencia de scraping
    # active con score alto â†’ daily
    # active con score medio â†’ weekly
    # inactive â†’ monthly (Ãºltima oportunidad)
    await adjust_all_scraping_frequencies()
```

---

## ğŸ’» Componentes de CÃ³digo

### 1. Discovery Connector
**Archivo:** `sources/discovery_connector.py`

```python
class DiscoveryConnector:
    """
    Descubre nuevas fuentes diariamente analizando noticias seed.
    """
    
    async def discover_from_perplexity(
        self, 
        location: str = "Euskadi, PaÃ­s Vasco", 
        count: int = 10
    ) -> List[str]:
        """
        Obtiene titulares seed desde Perplexity.
        
        Returns:
            Lista de titulares con snippets
        """
        pass
    
    async def find_original_source(
        self, 
        headline: str, 
        snippet: str
    ) -> Optional[str]:
        """
        Busca la fuente original con Google Custom Search.
        
        Args:
            headline: Titular de la noticia
            snippet: Extracto de la noticia
            
        Returns:
            URL de la fuente original (no medios conocidos)
        """
        pass
    
    async def validate_source(self, url: str) -> bool:
        """
        Valida que la fuente sea scrapeble y sin copyright.
        
        Checks:
        - robots.txt permite scraping
        - No tiene copyright restrictivo
        - Es una sala de prensa/noticias corporativa
        
        Returns:
            True si pasa todas las validaciones
        """
        pass
    
    async def extract_contact_info(
        self, 
        url: str, 
        html: str
    ) -> Dict[str, str]:
        """
        Extrae informaciÃ³n de contacto con LLM.
        
        Returns:
            {
                "source_name": "...",
                "contact_name": "...",
                "contact_email": "...",
                "contact_phone": "...",
                "contact_address": "..."
            }
        """
        pass
    
    async def evaluate_initial_quality(
        self, 
        content: str
    ) -> float:
        """
        EvalÃºa calidad inicial del contenido con LLM.
        
        Returns:
            Score 0-1 de riqueza informativa
        """
        pass
    
    async def create_discovered_source(
        self,
        company_id: str,
        url: str,
        contact_info: Dict,
        initial_quality: float,
        discovered_from: str,
        headline: str
    ) -> str:
        """
        Crea discovered_source en BD y source para scraping.
        
        Returns:
            discovered_source_id
        """
        pass
```

### 2. Source Relevance Calculator
**Archivo:** `utils/source_relevance.py`

```python
class SourceRelevanceCalculator:
    """
    Calcula y actualiza scores de relevancia.
    """
    
    def calculate_relevance_score(self, source: Dict) -> float:
        """
        Calcula score de 0 a 1 basado en 3 factores.
        
        Factor 1: Uso del cliente (40%)
        Factor 2: Frecuencia de contenido (30%)
        Factor 3: Calidad del contenido (30%)
        """
        # Factor 1: Uso del cliente
        articles_score = min(source["articles_published_count"] / 10, 1.0)
        usage_score = articles_score * 0.4
        
        # Factor 2: Frecuencia de contenido
        frequency_score = self._calculate_frequency_score(source)
        frequency_score *= 0.3
        
        # Factor 3: Calidad del contenido
        quality_score = (source["avg_content_quality_score"] or 0.5) * 0.3
        
        return round(usage_score + frequency_score + quality_score, 2)
    
    def _calculate_frequency_score(self, source: Dict) -> float:
        """Calcula score de frecuencia con penalizaciones."""
        if not source["avg_content_frequency_days"]:
            return 0.5
        
        days = source["avg_content_frequency_days"]
        
        if days <= 7:
            base_score = 1.0
        elif days <= 30:
            base_score = 0.6
        else:
            base_score = 0.3
        
        # Penalizar si no hay contenido reciente
        if source["last_content_date"]:
            days_since = (datetime.now() - source["last_content_date"]).days
            if days_since > 60:
                base_score *= 0.3
            elif days_since > 30:
                base_score *= 0.7
        
        return base_score
    
    async def evaluate_content_quality(
        self, 
        content_unit: Dict
    ) -> float:
        """
        EvalÃºa calidad de un content_unit con LLM.
        
        Criterios:
        - Riqueza de informaciÃ³n (datos, cifras, nombres)
        - NÃºmero de atomic_statements
        - Presencia de quotes
        - Novedad/relevancia temporal
        
        Returns:
            Score 0-1
        """
        pass
    
    async def update_source_metrics(
        self,
        discovered_source_id: str,
        new_quality_score: float,
        content_date: datetime
    ):
        """
        Actualiza mÃ©tricas tras scrapear contenido nuevo.
        """
        pass
    
    async def recalculate_relevance(
        self, 
        discovered_source_id: str
    ):
        """
        Recalcula y actualiza relevance_score en BD.
        """
        pass
```

### 3. Source Lifecycle Manager
**Archivo:** `utils/source_lifecycle.py`

```python
class SourceLifecycleManager:
    """
    Gestiona el ciclo de vida de discovered_sources.
    """
    
    async def promote_trials_to_active(self):
        """
        Promociona sources en trial que superan periodo de prueba.
        
        CondiciÃ³n: trial_ends_at < NOW() AND score > 0.5
        """
        pass
    
    async def demote_active_to_inactive(self):
        """
        Degrada sources activas sin contenido reciente.
        
        CondiciÃ³n: last_content_date < NOW() - 60 dÃ­as
        """
        pass
    
    async def archive_inactive_sources(self):
        """
        Archiva sources inactivas sin recuperaciÃ³n.
        
        CondiciÃ³n: 
        - status = inactive
        - last_content_date < NOW() - 90 dÃ­as
        - score < 0.3
        """
        pass
    
    async def adjust_scraping_frequency(
        self, 
        discovered_source_id: str
    ):
        """
        Ajusta frecuencia de scraping segÃºn relevancia.
        
        Rules:
        - score > 0.7 â†’ daily
        - score 0.5-0.7 â†’ daily
        - score 0.3-0.5 â†’ weekly
        - score < 0.3 â†’ monthly
        """
        pass
    
    async def adjust_all_scraping_frequencies(self):
        """
        EvalÃºa y ajusta frecuencias de todas las sources.
        """
        pass
```

### 4. Usage Tracker
**Archivo:** `utils/discovery_usage_tracker.py`

```python
class DiscoveryUsageTracker:
    """
    Trackea uso de discovered_sources al publicar artÃ­culos.
    """
    
    async def track_article_publication(self, article_id: str):
        """
        Incrementa articles_published_count de sources usadas.
        
        Identifica discovered_sources a partir de:
        - press_articles.news_ids â†’ press_context_units
        - press_context_units.source_metadata.url â†’ discovered_sources
        """
        pass
    
    async def get_sources_from_article(
        self, 
        article_id: str
    ) -> List[str]:
        """
        Extrae discovered_source_ids usadas en un artÃ­culo.
        """
        pass
    
    async def increment_usage_count(
        self, 
        discovered_source_id: str
    ):
        """
        Incrementa articles_published_count y actualiza timestamp.
        """
        pass
```

---

## ğŸ“… Plan de ImplementaciÃ³n

### Sprint 1: Core Discovery (3-4 dÃ­as)

**Objetivo:** Sistema bÃ¡sico de descubrimiento funcionando

**Tareas:**
1. âœ… Crear tabla `discovered_sources` (migraciÃ³n SQL)
2. âœ… Implementar `DiscoveryConnector`:
   - `discover_from_perplexity()`
   - `find_original_source()` con Google Custom Search
   - `validate_source()` (robots.txt, copyright)
   - `extract_contact_info()` (LLM)
   - `evaluate_initial_quality()` (LLM)
   - `create_discovered_source()`
3. âœ… AÃ±adir job diario al scheduler (`6:00 UTC`)
4. âœ… Testing: Descubrir 3-5 fuentes manualmente
5. âœ… Logging completo de discovery pipeline

**Entregables:**
- MigraciÃ³n SQL: `sql/migrations/add_discovered_sources.sql`
- CÃ³digo: `sources/discovery_connector.py`
- Job scheduler actualizado: `scheduler.py`
- CLI test: `python cli.py run-discovery`

---

### Sprint 2: Relevance Engine (2-3 dÃ­as)

**Objetivo:** Sistema de scoring y evaluaciÃ³n de calidad

**Tareas:**
1. âœ… Implementar `SourceRelevanceCalculator`:
   - `calculate_relevance_score()`
   - `evaluate_content_quality()` (LLM)
   - `update_source_metrics()`
   - `recalculate_relevance()`
2. âœ… Hook en scraper workflow:
   - Callback `on_content_scraped()`
   - Actualizar mÃ©tricas tras cada scraping
3. âœ… Implementar `SourceLifecycleManager`:
   - `promote_trials_to_active()`
   - `demote_active_to_inactive()`
   - `archive_inactive_sources()`
   - `adjust_scraping_frequency()`
4. âœ… AÃ±adir job semanal al scheduler (`Lunes 3:00 UTC`)
5. âœ… Testing: Evaluar ciclo completo con fuentes de prueba

**Entregables:**
- CÃ³digo: `utils/source_relevance.py`
- CÃ³digo: `utils/source_lifecycle.py`
- Hook integrado en: `sources/scraper_workflow.py`
- Job scheduler actualizado: `scheduler.py`

---

### Sprint 3: Usage Tracking & UI (2-3 dÃ­as)

**Objetivo:** Trackear uso real y exponer en API/Frontend

**Tareas:**
1. âœ… Implementar `DiscoveryUsageTracker`:
   - `track_article_publication()`
   - `get_sources_from_article()`
   - `increment_usage_count()`
2. âœ… Hook en artÃ­culos:
   - Callback al crear/publicar `press_articles`
   - Identificar sources usadas
3. âœ… API endpoints:
   - `GET /api/v1/discovered-sources` (listing con filtros)
   - `GET /api/v1/discovered-sources/{id}` (detalle)
   - `PATCH /api/v1/discovered-sources/{id}` (editar contacto)
   - `POST /api/v1/discovered-sources/{id}/pause` (pausar scraping)
4. âœ… CLI admin:
   - `python cli.py list-discovered --sort-by relevance`
   - `python cli.py source-stats {id}`
5. âœ… Testing end-to-end

**Entregables:**
- CÃ³digo: `utils/discovery_usage_tracker.py`
- API endpoints en: `server.py`
- CLI commands en: `cli.py`
- DocumentaciÃ³n API: actualizar `/docs`

---

### Sprint 4 (Opcional): Frontend UI (3-4 dÃ­as)

**Objetivo:** Interfaz para gestionar discovered sources

**Tareas:**
1. âœ… PÃ¡gina "Fuentes Descubiertas"
2. âœ… Listado con filtros (status, relevancia, tipo)
3. âœ… Cards con info de contacto y mÃ©tricas
4. âœ… Acciones: Ver noticias, Editar contacto, Pausar
5. âœ… Indicadores visuales de score y frecuencia

**Entregables:**
- Frontend integrado
- UX testeada con periodistas

---

## ğŸª Ejemplo de Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃA 1: DISCOVERY                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 06:00 - Job Discovery ejecuta                          â”‚
â”‚ â”œâ”€ Perplexity: "Ayuntamiento Laudio biblioteca"        â”‚
â”‚ â”œâ”€ Google: https://laudio.eus/noticias/biblioteca-2024 â”‚
â”‚ â”œâ”€ ValidaciÃ³n: âœ… robots.txt, âœ… copyright             â”‚
â”‚ â”œâ”€ Contacto: "Ayuntamiento Laudio", email, telÃ©fono   â”‚
â”‚ â”œâ”€ Calidad LLM: 0.7                                    â”‚
â”‚ â””â”€ Crea discovered_source:                             â”‚
â”‚    - status: trial                                     â”‚
â”‚    - relevance_score: 0.5 (inicial)                    â”‚
â”‚    - contact info completo                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃA 2-30: TRIAL PERIOD                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Scraping diario de laudio.eus/noticias               â”‚
â”‚ - 8 noticias scrapeadas                                â”‚
â”‚ - Calidad promedio: 0.75                               â”‚
â”‚ - Frecuencia: 1 cada 3.7 dÃ­as                          â”‚
â”‚ - Score: 0.43 (0 + 0.30*0.9 + 0.30*0.75)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃA 31: EVALUACIÃ“N LIFECYCLE                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - Lunes 03:00 - Job Lifecycle ejecuta                  â”‚
â”‚ - Periodista publicÃ³ 2 artÃ­culos usando esta fuente    â”‚
â”‚ - Score recalculado: 0.08 + 0.27 + 0.23 = 0.58        â”‚
â”‚ - PromociÃ³n: trial â†’ active âœ…                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃA 90: FUENTE CONSOLIDADA                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - 5 artÃ­culos publicados por periodista                â”‚
â”‚ - 30 noticias scrapeadas                               â”‚
â”‚ - Calidad promedio: 0.80                               â”‚
â”‚ - Frecuencia: cada 3 dÃ­as                              â”‚
â”‚ - Score: 0.20 + 0.30 + 0.24 = 0.74                     â”‚
â”‚ - â­ FUENTE PRIORITARIA (scraping daily)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃA 150: DECAIMIENTO                                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - 0 contenido nuevo en 60 dÃ­as                         â”‚
â”‚ - Score recalculado: 0.20 + 0.09 + 0.24 = 0.53        â”‚
â”‚ - DegradaciÃ³n: scraping daily â†’ weekly                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃA 200: INACTIVACIÃ“N                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - 0 contenido nuevo en 110 dÃ­as                        â”‚
â”‚ - Score: 0.20 + 0.03 + 0.24 = 0.47                     â”‚
â”‚ - Estado: active â†’ inactive                            â”‚
â”‚ - Scraping: weekly â†’ monthly (Ãºltima oportunidad)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DÃA 250: ARCHIVO                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ - 0 contenido nuevo en 160 dÃ­as                        â”‚
â”‚ - Score: 0.20 + 0.01 + 0.24 = 0.45 â†’ 0.27             â”‚
â”‚ - Score < 0.3 y >90 dÃ­as inactivo                      â”‚
â”‚ - Estado: inactive â†’ archived âš°ï¸                       â”‚
â”‚ - Scraping: DETENIDO                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” Casos de Uso

### Caso 1: Ayuntamiento Activo
**Fuente:** Ayuntamiento de Vitoria-Gasteiz  
**Resultado Esperado:** Score alto (0.7-0.9), scraping diario

- Publican 2-3 noticias/semana
- Periodista usa frecuentemente (8 artÃ­culos publicados)
- Contenido de calidad alta (ruedas de prensa, datos oficiales)
- **Score:** 0.32 + 0.30 + 0.27 = **0.89** â­â­â­â­â­

### Caso 2: Empresa con Sala de Prensa Regular
**Fuente:** Tubacex  
**Resultado Esperado:** Score medio-alto (0.6-0.8), scraping diario/semanal

- Publican 1 noticia/semana
- Periodista usa ocasionalmente (5 artÃ­culos)
- Contenido corporativo de calidad media-alta
- **Score:** 0.20 + 0.27 + 0.25 = **0.72** â­â­â­â­

### Caso 3: FundaciÃ³n Irregular
**Fuente:** FundaciÃ³n BBK  
**Resultado Esperado:** Score medio (0.4-0.6), scraping semanal

- Publican 1-2 noticias/mes
- Periodista no ha usado aÃºn (0 artÃ­culos)
- Contenido de calidad media
- **Score:** 0.00 + 0.18 + 0.18 = **0.36** â­â­

### Caso 4: Ayuntamiento Inactivo
**Fuente:** Ayuntamiento pequeÃ±o sin actividad  
**Resultado Esperado:** Score bajo (0.2-0.4), archivado

- Ãšltima noticia hace 4 meses
- Periodista no usa (0 artÃ­culos)
- Contenido escaso
- **Score:** 0.00 + 0.03 + 0.15 = **0.18** â†’ **ARCHIVED**

---

## ğŸ“Š MÃ©tricas de Ã‰xito

### KPIs del Sistema

1. **Tasa de Descubrimiento**
   - Target: 3-5 fuentes nuevas/dÃ­a
   - MÃ©trica: `discovered_sources` creadas por dÃ­a

2. **Tasa de ActivaciÃ³n**
   - Target: >40% de trials â†’ active
   - MÃ©trica: Ratio trials promovidas / trials creadas

3. **Tasa de Uso**
   - Target: >30% de fuentes usadas en artÃ­culos
   - MÃ©trica: Fuentes con `articles_published_count > 0` / total activas

4. **Cobertura de Contactos**
   - Target: >80% de fuentes con email contacto
   - MÃ©trica: Fuentes con `contact_email != NULL` / total

5. **Eficiencia de Scraping**
   - Target: >60% de fuentes activas con contenido nuevo mensual
   - MÃ©trica: Fuentes con `last_content_date` < 30 dÃ­as / total activas

---

## ğŸš¨ Consideraciones y Riesgos

### Riesgos TÃ©cnicos

1. **Falsos Positivos en Discovery**
   - Riesgo: Descubrir pÃ¡ginas que no son salas de prensa
   - MitigaciÃ³n: ValidaciÃ³n estricta con heurÃ­sticas + LLM

2. **Sobrecarga de Scraping**
   - Riesgo: Acumular 100s de fuentes â†’ costos altos
   - MitigaciÃ³n: Lifecycle automÃ¡tico, archivado agresivo

3. **ExtracciÃ³n de Contacto Incorrecta**
   - Riesgo: LLM extrae datos errÃ³neos
   - MitigaciÃ³n: UI permite ediciÃ³n manual + validaciÃ³n email

### Riesgos Legales

1. **Copyright Infringement**
   - Riesgo: Scrapear contenido con copyright restrictivo
   - MitigaciÃ³n: ValidaciÃ³n inline pre-ingesta, disclaimer en UI

2. **Robots.txt Violations**
   - Riesgo: Scrapear sitios que prohiben bots
   - MitigaciÃ³n: VerificaciÃ³n obligatoria pre-ingesta

3. **GDPR - Datos de Contacto**
   - Riesgo: Almacenar datos personales sin consentimiento
   - MitigaciÃ³n: Solo datos pÃºblicos de organizaciones (no personas fÃ­sicas)

### Riesgos de Producto

1. **Baja AdopciÃ³n por Periodistas**
   - Riesgo: Periodistas no usan fuentes descubiertas
   - MitigaciÃ³n: UI intuitiva, destacar fuentes relevantes, notificaciones

2. **Calidad Baja de Fuentes**
   - Riesgo: Descubrir fuentes poco relevantes
   - MitigaciÃ³n: Scoring estricto, threshold alto para promotion

---

## ğŸ“š Referencias TÃ©cnicas

### APIs Externas

1. **Perplexity API**
   - Endpoint: `https://api.perplexity.ai/chat/completions`
   - Modelo: `sonar`
   - Costo: ~$0.001/request

2. **Google Custom Search API**
   - Endpoint: `https://www.googleapis.com/customsearch/v1`
   - LÃ­mite: 100 queries/dÃ­a (free tier)
   - Costo: $5/1000 queries (paid tier)

3. **Groq LLM**
   - Modelo: `llama-3.3-70b-versatile`
   - Uso: Contact extraction, quality evaluation
   - Costo: Free (rate limited)

### LibrerÃ­as Python

- `beautifulsoup4`: HTML parsing
- `urllib.robotparser`: robots.txt checking
- `langchain`: LLM orchestration
- `aiohttp`: Async HTTP requests
- `apscheduler`: Job scheduling

---

## ğŸ¯ PrÃ³ximos Pasos

### Inmediatos (Esta Semana)
1. Revisar y aprobar este plan
2. Crear migraciÃ³n SQL `discovered_sources`
3. Implementar `DiscoveryConnector` bÃ¡sico
4. Testing manual con 5 fuentes

### Corto Plazo (PrÃ³ximas 2 Semanas)
1. Completar Sprint 1 (Core Discovery)
2. Completar Sprint 2 (Relevance Engine)
3. Monitoring de primeras 20-30 fuentes descubiertas

### Medio Plazo (PrÃ³ximo Mes)
1. Completar Sprint 3 (Usage Tracking & API)
2. Analizar mÃ©tricas de Ã©xito
3. Ajustar algoritmo de scoring segÃºn feedback

### Largo Plazo (PrÃ³ximos 3 Meses)
1. Sprint 4 opcional (Frontend UI)
2. Escalar a 100+ fuentes activas
3. Evaluar expansiÃ³n geogrÃ¡fica (Gipuzkoa, Bizkaia)

---

**Documento preparado por:** Claude Code  
**Fecha:** 2 Diciembre 2024  
**VersiÃ³n:** 1.0
